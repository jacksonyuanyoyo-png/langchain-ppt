{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/wtf-langchain/blob/main/04_Prompts/04_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkIusM-GD9MR"
      },
      "source": [
        "# 04 æç¤ºè¯\n",
        "\n",
        "## ä»€ä¹ˆæ˜¯æç¤ºè¯ï¼Ÿ\n",
        "\n",
        "æç¤ºè¯ï¼ˆ`Prompt`ï¼‰æ˜¯æŒ‡å‘æ¨¡å‹æä¾›çš„è¾“å…¥ã€‚è¿™ä¸ªè¾“å…¥é€šå¸¸ç”±å¤šä¸ªå…ƒç´ æ„æˆã€‚`LangChain` æä¾›äº†ä¸€ç³»åˆ—çš„ç±»å’Œå‡½æ•°ï¼Œç®€åŒ–æ„å»ºå’Œå¤„ç†æç¤ºè¯çš„è¿‡ç¨‹ã€‚\n",
        "- æç¤ºè¯æ¨¡æ¿ï¼ˆPrompt Templateï¼‰ï¼šå¯¹æç¤ºè¯å‚æ•°åŒ–ï¼Œæé«˜ä»£ç çš„é‡ç”¨æ€§ã€‚\n",
        "- ç¤ºä¾‹é€‰æ‹©å™¨ï¼ˆExample Selectorï¼‰ï¼šåŠ¨æ€é€‰æ‹©è¦åŒ…å«åœ¨æç¤ºè¯ä¸­çš„ç¤ºä¾‹\n",
        "\n",
        "## æç¤ºè¯æ¨¡æ¿\n",
        "\n",
        "æç¤ºè¯æ¨¡æ¿æä¾›äº†å¯é‡ç”¨æç¤ºè¯çš„æœºåˆ¶ã€‚ç”¨æˆ·é€šè¿‡ä¼ é€’ä¸€ç»„å‚æ•°ç»™æ¨¡æ¿ï¼Œå®ä¾‹åŒ–å›¾ä¸€ä¸ªæç¤ºè¯ã€‚ä¸€ä¸ªæç¤ºæ¨¡æ¿å¯ä»¥åŒ…å«ï¼š\n",
        "1. å¯¹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤\n",
        "2. ä¸€ç»„å°‘æ ·æœ¬ç¤ºä¾‹ï¼Œä»¥å¸®åŠ©è¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´å¥½çš„å›å¤\n",
        "3. å‘è¯­è¨€æ¨¡å‹æå‡ºçš„é—®é¢˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceq3MMqkDutF",
        "outputId": "b71546ca-c764-40db-b8e9-c75da5aa357f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JLEcB491EGTI",
        "outputId": "e01c7610-0776-4801-be39-b8d6816ee207"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nä½ ç²¾é€šå¤šç§è¯­è¨€ï¼Œæ˜¯ä¸“ä¸šçš„ç¿»è¯‘å®˜ã€‚ä½ è´Ÿè´£è‹±æ–‡åˆ°ä¸­æ–‡çš„ç¿»è¯‘å·¥ä½œã€‚\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "template = \"\"\"\n",
        "ä½ ç²¾é€šå¤šç§è¯­è¨€ï¼Œæ˜¯ä¸“ä¸šçš„ç¿»è¯‘å®˜ã€‚ä½ è´Ÿè´£{src_lang}åˆ°{dst_lang}çš„ç¿»è¯‘å·¥ä½œã€‚\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt.format(src_lang=\"è‹±æ–‡\", dst_lang=\"ä¸­æ–‡\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DRl_mS9EUl8"
      },
      "source": [
        "### åˆ›å»ºæ¨¡æ¿\n",
        "\n",
        "`PromptTemplate` ç±»æ˜¯ `LangChain` æä¾›çš„æ¨¡ç‰ˆåŸºç¡€ç±»ï¼Œå®ƒæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼š\n",
        "1. `input_variables` - è¾“å…¥å˜é‡\n",
        "2. `template` - æ¨¡ç‰ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T349YtlREVlc",
        "outputId": "682a2e75-18f9-4aba-b2d6-18e2e5d7b07a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A black bear .'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiple_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"animal\"],\n",
        "    template=\"A {color} {animal} .\"\n",
        ")\n",
        "multiple_input_prompt.format(color=\"black\", animal=\"bear\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLaylT92Eeu_"
      },
      "source": [
        "#### èŠå¤©æç¤ºè¯æ¨¡æ¿\n",
        "\n",
        "èŠå¤©æ¨¡å‹ï¼Œæ¯”å¦‚ `OpenAI` çš„GPTæ¨¡å‹ï¼Œæ¥å—ä¸€ç³»åˆ—èŠå¤©æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œæ¯æ¡æ¶ˆæ¯éƒ½ä¸ä¸€ä¸ªè§’è‰²ç›¸å…³è”ã€‚è¿™ä¸ªæ¶ˆæ¯åˆ—è¡¨é€šå¸¸ä»¥ä¸€å®šæ ¼å¼ä¸²è”ï¼Œæ„æˆæ¨¡å‹çš„è¾“å…¥ï¼Œä¹Ÿå°±æ˜¯æç¤ºè¯ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_VDH6iEjY8",
        "outputId": "3b1cad37-3375-4b50-9ebe-505b7085d471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a professional translator that translates English to Chinese.', additional_kwargs={}),\n",
              " HumanMessage(content='Did you eat in this morning?', additional_kwargs={}, example=False)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "human_template=\"{user_input}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "chat_prompt.format_prompt(\n",
        "    src_lang=\"English\",\n",
        "    dst_lang=\"Chinese\",\n",
        "    user_input=\"Did you eat in this morning?\"\n",
        ").to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL1RwGrXEyKg"
      },
      "source": [
        "#### æ ·æœ¬é€‰æ‹©å™¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aei66914EywY",
        "outputId": "51606e73-35a0-4d95-9714-31cba534862a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: big\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "# å®šä¹‰åä¹‰è¯ç¤ºä¾‹æ•°æ®\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "]\n",
        "\n",
        "# å®šä¹‰ç¤ºä¾‹çš„æ ¼å¼æ¨¡æ¿\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# åˆ›å»ºåŸºäºé•¿åº¦çš„ç¤ºä¾‹é€‰æ‹©å™¨\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    # å¯é€‰çš„æ ·æœ¬æ•°æ®\n",
        "    examples=examples,\n",
        "    # æç¤ºè¯æ¨¡ç‰ˆ\n",
        "    example_prompt=example_prompt,\n",
        "    # æ ¼å¼åŒ–çš„æ ·æœ¬æ•°æ®çš„æœ€å¤§é•¿åº¦ï¼Œé€šè¿‡get_text_lengthå‡½æ•°æ¥è¡¡é‡\n",
        "    max_length=25,  # ä¿®æ­£ï¼šå¢åŠ æœ€å¤§é•¿åº¦ä»¥æ˜¾ç¤ºæ›´å¤šç¤ºä¾‹\n",
        ")\n",
        "\n",
        "# åˆ›å»ºå°‘æ ·æœ¬æç¤ºæ¨¡æ¿\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    input_variables=[\"adjective\"],\n",
        ")\n",
        "\n",
        "print(\"=== çŸ­è¾“å…¥ç¤ºä¾‹ï¼ˆä¼šé€‰æ‹©æ›´å¤šæ ·æœ¬ï¼‰===\")\n",
        "print(dynamic_prompt.format(adjective=\"big\"))\n",
        "\n",
        "print(\"\\n=== é•¿è¾“å…¥ç¤ºä¾‹ï¼ˆä¼šé€‰æ‹©è¾ƒå°‘æ ·æœ¬ï¼‰===\")\n",
        "long_input = \"big and enormous and huge and massive and gigantic and extremely large\"\n",
        "print(dynamic_prompt.format(adjective=long_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®©æˆ‘ä»¬æ·±å…¥äº†è§£ç¤ºä¾‹é€‰æ‹©å™¨æ˜¯å¦‚ä½•å·¥ä½œçš„\n",
        "print(\"=== ç¤ºä¾‹é€‰æ‹©å™¨å·¥ä½œåŸç†åˆ†æ ===\")\n",
        "print(f\"ç©ºå­—ç¬¦ä¸²çš„é•¿åº¦: {example_selector.get_text_length('')}\")\n",
        "print(f\"'big'çš„é•¿åº¦: {example_selector.get_text_length('big')}\")\n",
        "print(f\"é•¿å­—ç¬¦ä¸²çš„é•¿åº¦: {example_selector.get_text_length(long_input)}\")\n",
        "\n",
        "print(\"\\n=== é€‰æ‹©å™¨ä¸ºä¸åŒè¾“å…¥é€‰æ‹©çš„ç¤ºä¾‹ ===\")\n",
        "# çŸ­è¾“å…¥\n",
        "short_examples = example_selector.select_examples({\"adjective\": \"big\"})\n",
        "print(f\"çŸ­è¾“å…¥'big'é€‰æ‹©çš„ç¤ºä¾‹æ•°é‡: {len(short_examples)}\")\n",
        "for i, example in enumerate(short_examples, 1):\n",
        "    print(f\"  ç¤ºä¾‹{i}: {example}\")\n",
        "\n",
        "# é•¿è¾“å…¥\n",
        "long_examples = example_selector.select_examples({\"adjective\": long_input})\n",
        "print(f\"\\né•¿è¾“å…¥é€‰æ‹©çš„ç¤ºä¾‹æ•°é‡: {len(long_examples)}\")\n",
        "for i, example in enumerate(long_examples, 1):\n",
        "    print(f\"  ç¤ºä¾‹{i}: {example}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### è¯­ä¹‰ç›¸ä¼¼åº¦ç¤ºä¾‹é€‰æ‹©å™¨\n",
        "\n",
        "é™¤äº†åŸºäºé•¿åº¦çš„é€‰æ‹©å™¨ï¼ŒLangChainè¿˜æä¾›åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„é€‰æ‹©å™¨ï¼Œå®ƒèƒ½æ ¹æ®è¾“å…¥çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ¥é€‰æ‹©æœ€ç›¸å…³çš„ç¤ºä¾‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ³¨æ„ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨éœ€è¦å®‰è£…é¢å¤–çš„ä¾èµ–åŒ…\n",
        "# è¿™é‡Œæˆ‘ä»¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ï¼ˆå®é™…è¿è¡Œéœ€è¦å®‰è£…å¯¹åº”çš„å‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹ï¼‰\n",
        "\n",
        "# from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# åˆ›å»ºæ›´ä¸°å¯Œçš„ç¤ºä¾‹æ•°æ®ç”¨äºè¯­ä¹‰æœç´¢\n",
        "semantic_examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\", \"context\": \"emotion\"},\n",
        "    {\"input\": \"joyful\", \"output\": \"miserable\", \"context\": \"emotion\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\", \"context\": \"height\"},\n",
        "    {\"input\": \"high\", \"output\": \"low\", \"context\": \"height\"},\n",
        "    {\"input\": \"fast\", \"output\": \"slow\", \"context\": \"speed\"},\n",
        "    {\"input\": \"quick\", \"output\": \"sluggish\", \"context\": \"speed\"},\n",
        "]\n",
        "\n",
        "print(\"=== è¯­ä¹‰ç›¸ä¼¼åº¦ç¤ºä¾‹é€‰æ‹©å™¨æ¦‚å¿µæ¼”ç¤º ===\")\n",
        "print(\"è¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨ä¼šæ ¹æ®è¾“å…¥ä¸ç¤ºä¾‹çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ¥é€‰æ‹©æœ€ç›¸å…³çš„ç¤ºä¾‹\")\n",
        "print(\"ä¾‹å¦‚ï¼š\")\n",
        "print(\"- è¾“å…¥'delighted'ï¼ˆé«˜å…´çš„ï¼‰ä¼šé€‰æ‹©æƒ…æ„Ÿç›¸å…³çš„ç¤ºä¾‹å¦‚'happy->sad'\")\n",
        "print(\"- è¾“å…¥'rapid'ï¼ˆå¿«é€Ÿçš„ï¼‰ä¼šé€‰æ‹©é€Ÿåº¦ç›¸å…³çš„ç¤ºä¾‹å¦‚'fast->slow'\")\n",
        "print(\"- è¾“å…¥'elevated'ï¼ˆé«˜çš„ï¼‰ä¼šé€‰æ‹©é«˜åº¦ç›¸å…³çš„ç¤ºä¾‹å¦‚'tall->short'\")\n",
        "\n",
        "# æ¼”ç¤ºåŸºäºå…³é”®è¯çš„ç®€åŒ–ç‰ˆæœ¬åŒ¹é…\n",
        "def simple_semantic_select(input_word, examples, k=2):\n",
        "    \"\"\"ç®€åŒ–ç‰ˆè¯­ä¹‰é€‰æ‹©å™¨æ¼”ç¤º\"\"\"\n",
        "    # å®šä¹‰è¯­ä¹‰å…³é”®è¯ç»„\n",
        "    emotion_words = [\"happy\", \"joyful\", \"delighted\", \"cheerful\", \"glad\"]\n",
        "    height_words = [\"tall\", \"high\", \"elevated\", \"towering\"]\n",
        "    speed_words = [\"fast\", \"quick\", \"rapid\", \"swift\"]\n",
        "    \n",
        "    # æ ¹æ®è¾“å…¥è¯åˆ¤æ–­ç±»åˆ«\n",
        "    if input_word.lower() in emotion_words:\n",
        "        category = \"emotion\"\n",
        "    elif input_word.lower() in height_words:\n",
        "        category = \"height\"\n",
        "    elif input_word.lower() in speed_words:\n",
        "        category = \"speed\"\n",
        "    else:\n",
        "        category = \"general\"\n",
        "    \n",
        "    # é€‰æ‹©ç›¸å…³ç¤ºä¾‹\n",
        "    selected = [ex for ex in examples if ex.get(\"context\", \"general\") == category]\n",
        "    return selected[:k] if selected else examples[:k]\n",
        "\n",
        "# æµ‹è¯•è¯­ä¹‰é€‰æ‹©\n",
        "test_words = [\"delighted\", \"elevated\", \"rapid\"]\n",
        "for word in test_words:\n",
        "    selected = simple_semantic_select(word, semantic_examples)\n",
        "    print(f\"\\nè¾“å…¥'{word}'é€‰æ‹©çš„ç¤ºä¾‹:\")\n",
        "    for example in selected:\n",
        "        print(f\"  {example['input']} -> {example['output']} (ç±»åˆ«: {example['context']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### å®é™…åº”ç”¨ç¤ºä¾‹ï¼šå¤šè¯­è¨€ç¿»è¯‘åŠ©æ‰‹\n",
        "\n",
        "è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ›´å®ç”¨çš„æç¤ºè¯æ¨¡æ¿ç³»ç»Ÿï¼Œç»“åˆåŠ¨æ€ç¤ºä¾‹é€‰æ‹©æ¥æ„å»ºä¸€ä¸ªæ™ºèƒ½ç¿»è¯‘åŠ©æ‰‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºç¿»è¯‘ç¤ºä¾‹æ•°æ®\n",
        "translation_examples = [\n",
        "    {\"english\": \"Hello, how are you?\", \"chinese\": \"ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ\", \"type\": \"greeting\"},\n",
        "    {\"english\": \"Good morning!\", \"chinese\": \"æ—©ä¸Šå¥½ï¼\", \"type\": \"greeting\"},\n",
        "    {\"english\": \"I love programming.\", \"chinese\": \"æˆ‘å–œæ¬¢ç¼–ç¨‹ã€‚\", \"type\": \"hobby\"},\n",
        "    {\"english\": \"Python is a great language.\", \"chinese\": \"Pythonæ˜¯ä¸€é—¨å¾ˆæ£’çš„è¯­è¨€ã€‚\", \"type\": \"technology\"},\n",
        "    {\"english\": \"Let's have dinner together.\", \"chinese\": \"æˆ‘ä»¬ä¸€èµ·åƒæ™šé¥­å§ã€‚\", \"type\": \"social\"},\n",
        "    {\"english\": \"The weather is nice today.\", \"chinese\": \"ä»Šå¤©å¤©æ°”ä¸é”™ã€‚\", \"type\": \"daily\"},\n",
        "]\n",
        "\n",
        "# åˆ›å»ºç¿»è¯‘ç¤ºä¾‹çš„æ¨¡æ¿\n",
        "translation_example_prompt = PromptTemplate(\n",
        "    input_variables=[\"english\", \"chinese\"],\n",
        "    template=\"English: {english}\\nChinese: {chinese}\"\n",
        ")\n",
        "\n",
        "# åŸºäºç±»å‹çš„ç®€å•é€‰æ‹©å™¨\n",
        "class TypeBasedExampleSelector:\n",
        "    def __init__(self, examples, k=3):\n",
        "        self.examples = examples\n",
        "        self.k = k\n",
        "    \n",
        "    def select_examples(self, input_variables):\n",
        "        # ç®€å•çš„å…³é”®è¯åŒ¹é…é€»è¾‘\n",
        "        text = input_variables.get(\"english\", \"\").lower()\n",
        "        \n",
        "        # æ ¹æ®å…³é”®è¯åˆ¤æ–­ç±»å‹\n",
        "        if any(word in text for word in [\"hello\", \"hi\", \"morning\", \"evening\"]):\n",
        "            example_type = \"greeting\"\n",
        "        elif any(word in text for word in [\"love\", \"like\", \"enjoy\"]):\n",
        "            example_type = \"hobby\"\n",
        "        elif any(word in text for word in [\"python\", \"programming\", \"code\", \"language\"]):\n",
        "            example_type = \"technology\"\n",
        "        elif any(word in text for word in [\"dinner\", \"lunch\", \"eat\", \"together\"]):\n",
        "            example_type = \"social\"\n",
        "        elif any(word in text for word in [\"weather\", \"today\", \"sunny\", \"rain\"]):\n",
        "            example_type = \"daily\"\n",
        "        else:\n",
        "            example_type = \"general\"\n",
        "        \n",
        "        # é€‰æ‹©ç›¸å…³ç¤ºä¾‹\n",
        "        relevant_examples = [ex for ex in self.examples if ex.get(\"type\") == example_type]\n",
        "        if not relevant_examples:\n",
        "            relevant_examples = self.examples\n",
        "        \n",
        "        return relevant_examples[:self.k]\n",
        "\n",
        "# åˆ›å»ºæ™ºèƒ½ç¿»è¯‘åŠ©æ‰‹\n",
        "translation_selector = TypeBasedExampleSelector(translation_examples, k=2)\n",
        "\n",
        "translation_prompt = FewShotPromptTemplate(\n",
        "    example_selector=translation_selector,\n",
        "    example_prompt=translation_example_prompt,\n",
        "    prefix=\"\"\"You are a professional English-Chinese translator. \n",
        "Based on the following examples, translate the given English text to Chinese.\n",
        "Pay attention to the context and style of the examples.\"\"\",\n",
        "    suffix=\"English: {english}\\nChinese:\",\n",
        "    input_variables=[\"english\"]\n",
        ")\n",
        "\n",
        "# æµ‹è¯•ä¸åŒç±»å‹çš„ç¿»è¯‘\n",
        "test_sentences = [\n",
        "    \"Good evening, everyone!\",\n",
        "    \"I enjoy learning new programming languages.\",\n",
        "    \"Python makes coding more efficient.\",\n",
        "    \"Would you like to have coffee with me?\"\n",
        "]\n",
        "\n",
        "print(\"=== æ™ºèƒ½ç¿»è¯‘åŠ©æ‰‹æ¼”ç¤º ===\")\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\nè¾“å…¥: {sentence}\")\n",
        "    print(\"ç”Ÿæˆçš„æç¤ºè¯:\")\n",
        "    print(translation_prompt.format(english=sentence))\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## è¿›é˜¶æŠ€å·§ä¸æœ€ä½³å®è·µ\n",
        "\n",
        "### 1. æç¤ºè¯æ¨¡æ¿çš„æœ€ä½³å®è·µ\n",
        "\n",
        "- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†å¤æ‚çš„æç¤ºè¯åˆ†è§£ä¸ºå¤šä¸ªå¯é‡ç”¨çš„ç»„ä»¶\n",
        "- **å‚æ•°éªŒè¯**ï¼šç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å‚æ•°éƒ½è¢«æ­£ç¡®ä¼ é€’\n",
        "- **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šæ ¹æ®ä¸åŒçš„ä½¿ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„ç¤ºä¾‹å’Œæ ¼å¼\n",
        "- **æ€§èƒ½ä¼˜åŒ–**ï¼šåˆç†è®¾ç½®ç¤ºä¾‹é€‰æ‹©å™¨çš„å‚æ•°ä»¥å¹³è¡¡æ•ˆæœå’Œæ•ˆç‡\n",
        "\n",
        "### 2. ç¤ºä¾‹é€‰æ‹©å™¨çš„é€‰æ‹©ç­–ç•¥\n",
        "\n",
        "- **LengthBasedExampleSelector**ï¼šé€‚ç”¨äºéœ€è¦æ§åˆ¶æç¤ºè¯é•¿åº¦çš„åœºæ™¯\n",
        "- **SemanticSimilarityExampleSelector**ï¼šé€‚ç”¨äºéœ€è¦æ ¹æ®è¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©ç¤ºä¾‹çš„åœºæ™¯\n",
        "- **MaxMarginalRelevanceExampleSelector**ï¼šå¹³è¡¡ç›¸ä¼¼åº¦å’Œå¤šæ ·æ€§\n",
        "- **è‡ªå®šä¹‰é€‰æ‹©å™¨**ï¼šæ ¹æ®ç‰¹å®šä¸šåŠ¡é€»è¾‘å®ç°å®šåˆ¶åŒ–çš„é€‰æ‹©ç­–ç•¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ¼”ç¤ºé«˜çº§æç¤ºè¯æ¨¡æ¿æŠ€å·§\n",
        "\n",
        "# 1. å¸¦æ¡ä»¶é€»è¾‘çš„æç¤ºè¯æ¨¡æ¿\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "conditional_template = \"\"\"\n",
        "ä½ æ˜¯ä¸€ä¸ª{role}ã€‚\n",
        "{%- if difficulty == \"beginner\" %}\n",
        "è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚\n",
        "{%- elif difficulty == \"advanced\" %}\n",
        "è¯·æä¾›æ·±å…¥çš„æŠ€æœ¯åˆ†æå’Œè¯¦ç»†è§£é‡Šã€‚\n",
        "{%- else %}\n",
        "è¯·æä¾›å¹³è¡¡çš„å›ç­”ï¼Œæ—¢æœ‰æ¦‚è¿°ä¹Ÿæœ‰ä¸€äº›æŠ€æœ¯ç»†èŠ‚ã€‚\n",
        "{%- endif %}\n",
        "\n",
        "ç”¨æˆ·é—®é¢˜ï¼š{question}\n",
        "\"\"\"\n",
        "\n",
        "# æ³¨æ„ï¼šä¸Šé¢çš„æ¨¡æ¿ä½¿ç”¨äº†Jinja2è¯­æ³•ï¼Œåœ¨å®é™…ä½¿ç”¨ä¸­éœ€è¦ç›¸åº”çš„æ¨¡æ¿å¼•æ“æ”¯æŒ\n",
        "\n",
        "# 2. å¤šå±‚æ¬¡éªŒè¯çš„æç¤ºè¯æ¨¡æ¿\n",
        "class ValidatedPromptTemplate:\n",
        "    def __init__(self, template, required_vars, optional_vars=None):\n",
        "        self.template = template\n",
        "        self.required_vars = required_vars\n",
        "        self.optional_vars = optional_vars or []\n",
        "    \n",
        "    def format(self, **kwargs):\n",
        "        # éªŒè¯å¿…éœ€å‚æ•°\n",
        "        missing_vars = [var for var in self.required_vars if var not in kwargs]\n",
        "        if missing_vars:\n",
        "            raise ValueError(f\"ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_vars}\")\n",
        "        \n",
        "        # è®¾ç½®å¯é€‰å‚æ•°çš„é»˜è®¤å€¼\n",
        "        for var in self.optional_vars:\n",
        "            if var not in kwargs:\n",
        "                kwargs[var] = \"\"\n",
        "        \n",
        "        return self.template.format(**kwargs)\n",
        "\n",
        "# åˆ›å»ºéªŒè¯æ¨¡æ¿\n",
        "validated_template = ValidatedPromptTemplate(\n",
        "    template=\"ä½œä¸º{role}ï¼Œè¯·å›ç­”å…³äº{topic}çš„é—®é¢˜ï¼š{question}ã€‚{additional_context}\",\n",
        "    required_vars=[\"role\", \"topic\", \"question\"],\n",
        "    optional_vars=[\"additional_context\"]\n",
        ")\n",
        "\n",
        "# æµ‹è¯•éªŒè¯åŠŸèƒ½\n",
        "try:\n",
        "    # æ­£ç¡®ä½¿ç”¨\n",
        "    prompt1 = validated_template.format(\n",
        "        role=\"Pythonä¸“å®¶\",\n",
        "        topic=\"æ•°æ®ç»“æ„\",\n",
        "        question=\"ä»€ä¹ˆæ˜¯å­—å…¸ï¼Ÿ\",\n",
        "        additional_context=\"è¯·ä¸¾ä¾‹è¯´æ˜ã€‚\"\n",
        "    )\n",
        "    print(\"âœ… æ­£ç¡®çš„æç¤ºè¯ç”Ÿæˆ:\")\n",
        "    print(prompt1)\n",
        "    \n",
        "    # ç¼ºå°‘å¿…éœ€å‚æ•°çš„æƒ…å†µ\n",
        "    prompt2 = validated_template.format(\n",
        "        role=\"Pythonä¸“å®¶\",\n",
        "        question=\"ä»€ä¹ˆæ˜¯å­—å…¸ï¼Ÿ\"\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(f\"\\nâŒ å‚æ•°éªŒè¯å¤±è´¥: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# 3. åŠ¨æ€è§’è‰²åˆ‡æ¢çš„æç¤ºè¯ç³»ç»Ÿ\n",
        "class RoleBasedPromptSystem:\n",
        "    def __init__(self):\n",
        "        self.roles = {\n",
        "            \"teacher\": {\n",
        "                \"prefix\": \"ä½œä¸ºä¸€åç»éªŒä¸°å¯Œçš„æ•™å¸ˆï¼Œ\",\n",
        "                \"style\": \"æ•™è‚²æ€§çš„ã€å¾ªåºæ¸è¿›çš„\",\n",
        "                \"examples\": [\"è®©æˆ‘æ¥è§£é‡Šä¸€ä¸‹...\", \"é¦–å…ˆæˆ‘ä»¬éœ€è¦ç†è§£...\"]\n",
        "            },\n",
        "            \"consultant\": {\n",
        "                \"prefix\": \"ä½œä¸ºä¸“ä¸šé¡¾é—®ï¼Œ\",\n",
        "                \"style\": \"åˆ†ææ€§çš„ã€è§£å†³æ–¹æ¡ˆå¯¼å‘çš„\",\n",
        "                \"examples\": [\"åŸºäºåˆ†æï¼Œæˆ‘å»ºè®®...\", \"ä»å•†ä¸šè§’åº¦æ¥çœ‹...\"]\n",
        "            },\n",
        "            \"friend\": {\n",
        "                \"prefix\": \"ä½œä¸ºä½ çš„æœ‹å‹ï¼Œ\",\n",
        "                \"style\": \"è½»æ¾å‹å¥½çš„ã€æ”¯æŒæ€§çš„\",\n",
        "                \"examples\": [\"æˆ‘è§‰å¾—...\", \"ä½ å¯ä»¥è¯•è¯•...\"]\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def create_prompt(self, role, topic, question):\n",
        "        role_info = self.roles.get(role, self.roles[\"teacher\"])\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "{role_info['prefix']}æˆ‘å°†ä»¥{role_info['style']}æ–¹å¼æ¥å›ç­”ä½ çš„é—®é¢˜ã€‚\n",
        "\n",
        "ä¸»é¢˜ï¼š{topic}\n",
        "é—®é¢˜ï¼š{question}\n",
        "\n",
        "å›ç­”æ–¹å¼ç¤ºä¾‹ï¼š{role_info['examples'][0]}\n",
        "\"\"\"\n",
        "        return prompt.strip()\n",
        "\n",
        "# æµ‹è¯•è§’è‰²åˆ‡æ¢ç³»ç»Ÿ\n",
        "role_system = RoleBasedPromptSystem()\n",
        "\n",
        "test_question = \"å¦‚ä½•å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Ÿ\"\n",
        "roles_to_test = [\"teacher\", \"consultant\", \"friend\"]\n",
        "\n",
        "print(\"=== åŠ¨æ€è§’è‰²åˆ‡æ¢æ¼”ç¤º ===\")\n",
        "for role in roles_to_test:\n",
        "    print(f\"\\nã€{role.upper()}è§’è‰²ã€‘\")\n",
        "    prompt = role_system.create_prompt(role, \"æœºå™¨å­¦ä¹ \", test_question)\n",
        "    print(prompt)\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ€§èƒ½ä¼˜åŒ–ä¸è°ƒè¯•æŠ€å·§\n",
        "\n",
        "### 1. æç¤ºè¯é•¿åº¦ä¼˜åŒ–\n",
        "- ç›‘æ§ç”Ÿæˆçš„æç¤ºè¯é•¿åº¦ï¼Œé¿å…è¶…å‡ºæ¨¡å‹çš„ä¸Šä¸‹æ–‡é™åˆ¶\n",
        "- ä½¿ç”¨ç¤ºä¾‹é€‰æ‹©å™¨åŠ¨æ€è°ƒæ•´ç¤ºä¾‹æ•°é‡\n",
        "- åˆç†è®¾ç½®`max_length`å‚æ•°ä»¥å¹³è¡¡æ•ˆæœå’Œæ•ˆç‡\n",
        "\n",
        "### 2. è°ƒè¯•å’Œæµ‹è¯•\n",
        "- æ‰“å°ç”Ÿæˆçš„å®Œæ•´æç¤ºè¯ä»¥éªŒè¯æ ¼å¼\n",
        "- æµ‹è¯•è¾¹ç•Œæƒ…å†µï¼ˆç©ºè¾“å…¥ã€è¶…é•¿è¾“å…¥ç­‰ï¼‰\n",
        "- éªŒè¯ç¤ºä¾‹é€‰æ‹©çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§\n",
        "\n",
        "### 3. ç¼“å­˜å’Œé‡ç”¨\n",
        "- å¯¹äºç›¸åŒå‚æ•°ç»„åˆï¼Œç¼“å­˜ç”Ÿæˆçš„æç¤ºè¯\n",
        "- é‡ç”¨ç»è¿‡éªŒè¯çš„ç¤ºä¾‹æ•°æ®é›†\n",
        "- æ¨¡å—åŒ–è®¾è®¡ä»¥æé«˜ä»£ç å¤ç”¨æ€§\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ€§èƒ½ä¼˜åŒ–å’Œè°ƒè¯•å·¥å…·æ¼”ç¤º\n",
        "\n",
        "class PromptAnalyzer:\n",
        "    \"\"\"æç¤ºè¯åˆ†æå’Œä¼˜åŒ–å·¥å…·\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.metrics = {}\n",
        "    \n",
        "    def analyze_prompt(self, prompt_text, name=\"unnamed\"):\n",
        "        \"\"\"åˆ†ææç¤ºè¯çš„å„é¡¹æŒ‡æ ‡\"\"\"\n",
        "        lines = prompt_text.split('\\n')\n",
        "        words = prompt_text.split()\n",
        "        \n",
        "        analysis = {\n",
        "            \"name\": name,\n",
        "            \"total_length\": len(prompt_text),\n",
        "            \"word_count\": len(words),\n",
        "            \"line_count\": len(lines),\n",
        "            \"avg_line_length\": sum(len(line) for line in lines) / len(lines) if lines else 0,\n",
        "            \"max_line_length\": max(len(line) for line in lines) if lines else 0\n",
        "        }\n",
        "        \n",
        "        self.metrics[name] = analysis\n",
        "        return analysis\n",
        "    \n",
        "    def compare_prompts(self, prompt1, prompt2, name1=\"Prompt 1\", name2=\"Prompt 2\"):\n",
        "        \"\"\"æ¯”è¾ƒä¸¤ä¸ªæç¤ºè¯çš„æŒ‡æ ‡\"\"\"\n",
        "        analysis1 = self.analyze_prompt(prompt1, name1)\n",
        "        analysis2 = self.analyze_prompt(prompt2, name2)\n",
        "        \n",
        "        print(f\"=== æç¤ºè¯æ¯”è¾ƒ: {name1} vs {name2} ===\")\n",
        "        print(f\"æ€»é•¿åº¦: {analysis1['total_length']} vs {analysis2['total_length']}\")\n",
        "        print(f\"è¯æ•°: {analysis1['word_count']} vs {analysis2['word_count']}\")\n",
        "        print(f\"è¡Œæ•°: {analysis1['line_count']} vs {analysis2['line_count']}\")\n",
        "        print(f\"å¹³å‡è¡Œé•¿: {analysis1['avg_line_length']:.1f} vs {analysis2['avg_line_length']:.1f}\")\n",
        "        \n",
        "        return analysis1, analysis2\n",
        "    \n",
        "    def suggest_optimization(self, prompt_text):\n",
        "        \"\"\"æä¾›ä¼˜åŒ–å»ºè®®\"\"\"\n",
        "        analysis = self.analyze_prompt(prompt_text)\n",
        "        suggestions = []\n",
        "        \n",
        "        if analysis['total_length'] > 2000:\n",
        "            suggestions.append(\"âš ï¸ æç¤ºè¯è¿‡é•¿ï¼Œå»ºè®®ç¼©çŸ­æˆ–ä½¿ç”¨ç¤ºä¾‹é€‰æ‹©å™¨\")\n",
        "        \n",
        "        if analysis['max_line_length'] > 100:\n",
        "            suggestions.append(\"ğŸ“ æŸäº›è¡Œè¿‡é•¿ï¼Œå»ºè®®åˆ†è¡Œæé«˜å¯è¯»æ€§\")\n",
        "        \n",
        "        if analysis['word_count'] < 10:\n",
        "            suggestions.append(\"ğŸ’¡ æç¤ºè¯å¯èƒ½è¿‡äºç®€å•ï¼Œå»ºè®®æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡\")\n",
        "        \n",
        "        return suggestions\n",
        "\n",
        "# ä½¿ç”¨åˆ†æå·¥å…·\n",
        "analyzer = PromptAnalyzer()\n",
        "\n",
        "# åˆ†æä¹‹å‰åˆ›å»ºçš„ç¿»è¯‘æç¤ºè¯\n",
        "sample_prompt = translation_prompt.format(english=\"Hello, how are you today?\")\n",
        "suggestions = analyzer.suggest_optimization(sample_prompt)\n",
        "\n",
        "print(\"=== æç¤ºè¯æ€§èƒ½åˆ†æ ===\")\n",
        "analysis = analyzer.analyze_prompt(sample_prompt, \"ç¿»è¯‘åŠ©æ‰‹æç¤ºè¯\")\n",
        "\n",
        "for key, value in analysis.items():\n",
        "    if key != \"name\":\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "if suggestions:\n",
        "    print(\"\\n=== ä¼˜åŒ–å»ºè®® ===\")\n",
        "    for suggestion in suggestions:\n",
        "        print(suggestion)\n",
        "else:\n",
        "    print(\"\\nâœ… æç¤ºè¯æŒ‡æ ‡è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–\")\n",
        "\n",
        "print(\"\\n=== è°ƒè¯•æŠ€å·§æ¼”ç¤º ===\")\n",
        "print(\"1. å®Œæ•´æç¤ºè¯é¢„è§ˆ:\")\n",
        "print(\"--- å¼€å§‹ ---\")\n",
        "print(sample_prompt)\n",
        "print(\"--- ç»“æŸ ---\")\n",
        "\n",
        "print(f\"\\n2. å­—ç¬¦è®¡æ•°: {len(sample_prompt)} å­—ç¬¦\")\n",
        "print(f\"3. Tokenä¼°ç®— (ç²—ç•¥): ~{len(sample_prompt.split()) * 1.3:.0f} tokens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vehXwrdxG08-",
        "outputId": "b8665780-fbf7-4329-dd3d-5e0602837bf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_selector.get_text_length(\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM7vOFz/ctj6hEBoPcJqCn6",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
