{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/wtf-langchain/blob/main/04_Prompts/04_Prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkIusM-GD9MR"
      },
      "source": [
        "# 04 提示词\n",
        "\n",
        "## 什么是提示词？\n",
        "\n",
        "提示词（`Prompt`）是指向模型提供的输入。这个输入通常由多个元素构成。`LangChain` 提供了一系列的类和函数，简化构建和处理提示词的过程。\n",
        "- 提示词模板（Prompt Template）：对提示词参数化，提高代码的重用性。\n",
        "- 示例选择器（Example Selector）：动态选择要包含在提示词中的示例\n",
        "\n",
        "## 提示词模板\n",
        "\n",
        "提示词模板提供了可重用提示词的机制。用户通过传递一组参数给模板，实例化图一个提示词。一个提示模板可以包含：\n",
        "1. 对语言模型的指令\n",
        "2. 一组少样本示例，以帮助语言模型生成更好的回复\n",
        "3. 向语言模型提出的问题"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceq3MMqkDutF",
        "outputId": "b71546ca-c764-40db-b8e9-c75da5aa357f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JLEcB491EGTI",
        "outputId": "e01c7610-0776-4801-be39-b8d6816ee207"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n你精通多种语言，是专业的翻译官。你负责英文到中文的翻译工作。\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "template = \"\"\"\n",
        "你精通多种语言，是专业的翻译官。你负责{src_lang}到{dst_lang}的翻译工作。\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt.format(src_lang=\"英文\", dst_lang=\"中文\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DRl_mS9EUl8"
      },
      "source": [
        "### 创建模板\n",
        "\n",
        "`PromptTemplate` 类是 `LangChain` 提供的模版基础类，它接收两个参数：\n",
        "1. `input_variables` - 输入变量\n",
        "2. `template` - 模版"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "T349YtlREVlc",
        "outputId": "682a2e75-18f9-4aba-b2d6-18e2e5d7b07a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A black bear .'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiple_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"animal\"],\n",
        "    template=\"A {color} {animal} .\"\n",
        ")\n",
        "multiple_input_prompt.format(color=\"black\", animal=\"bear\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLaylT92Eeu_"
      },
      "source": [
        "#### 聊天提示词模板\n",
        "\n",
        "聊天模型，比如 `OpenAI` 的GPT模型，接受一系列聊天消息作为输入，每条消息都与一个角色相关联。这个消息列表通常以一定格式串联，构成模型的输入，也就是提示词。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_VDH6iEjY8",
        "outputId": "3b1cad37-3375-4b50-9ebe-505b7085d471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are a professional translator that translates English to Chinese.', additional_kwargs={}),\n",
              " HumanMessage(content='Did you eat in this morning?', additional_kwargs={}, example=False)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "system_template=\"You are a professional translator that translates {src_lang} to {dst_lang}.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "human_template=\"{user_input}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "chat_prompt.format_prompt(\n",
        "    src_lang=\"English\",\n",
        "    dst_lang=\"Chinese\",\n",
        "    user_input=\"Did you eat in this morning?\"\n",
        ").to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL1RwGrXEyKg"
      },
      "source": [
        "#### 样本选择器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aei66914EywY",
        "outputId": "51606e73-35a0-4d95-9714-31cba534862a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: big\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "# 定义反义词示例数据\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "]\n",
        "\n",
        "# 定义示例的格式模板\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# 创建基于长度的示例选择器\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    # 可选的样本数据\n",
        "    examples=examples,\n",
        "    # 提示词模版\n",
        "    example_prompt=example_prompt,\n",
        "    # 格式化的样本数据的最大长度，通过get_text_length函数来衡量\n",
        "    max_length=25,  # 修正：增加最大长度以显示更多示例\n",
        ")\n",
        "\n",
        "# 创建少样本提示模板\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    input_variables=[\"adjective\"],\n",
        ")\n",
        "\n",
        "print(\"=== 短输入示例（会选择更多样本）===\")\n",
        "print(dynamic_prompt.format(adjective=\"big\"))\n",
        "\n",
        "print(\"\\n=== 长输入示例（会选择较少样本）===\")\n",
        "long_input = \"big and enormous and huge and massive and gigantic and extremely large\"\n",
        "print(dynamic_prompt.format(adjective=long_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 让我们深入了解示例选择器是如何工作的\n",
        "print(\"=== 示例选择器工作原理分析 ===\")\n",
        "print(f\"空字符串的长度: {example_selector.get_text_length('')}\")\n",
        "print(f\"'big'的长度: {example_selector.get_text_length('big')}\")\n",
        "print(f\"长字符串的长度: {example_selector.get_text_length(long_input)}\")\n",
        "\n",
        "print(\"\\n=== 选择器为不同输入选择的示例 ===\")\n",
        "# 短输入\n",
        "short_examples = example_selector.select_examples({\"adjective\": \"big\"})\n",
        "print(f\"短输入'big'选择的示例数量: {len(short_examples)}\")\n",
        "for i, example in enumerate(short_examples, 1):\n",
        "    print(f\"  示例{i}: {example}\")\n",
        "\n",
        "# 长输入\n",
        "long_examples = example_selector.select_examples({\"adjective\": long_input})\n",
        "print(f\"\\n长输入选择的示例数量: {len(long_examples)}\")\n",
        "for i, example in enumerate(long_examples, 1):\n",
        "    print(f\"  示例{i}: {example}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 语义相似度示例选择器\n",
        "\n",
        "除了基于长度的选择器，LangChain还提供基于语义相似度的选择器，它能根据输入的语义相似度来选择最相关的示例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 注意：语义相似度选择器需要安装额外的依赖包\n",
        "# 这里我们演示如何使用（实际运行需要安装对应的向量数据库和嵌入模型）\n",
        "\n",
        "# from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# 创建更丰富的示例数据用于语义搜索\n",
        "semantic_examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\", \"context\": \"emotion\"},\n",
        "    {\"input\": \"joyful\", \"output\": \"miserable\", \"context\": \"emotion\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\", \"context\": \"height\"},\n",
        "    {\"input\": \"high\", \"output\": \"low\", \"context\": \"height\"},\n",
        "    {\"input\": \"fast\", \"output\": \"slow\", \"context\": \"speed\"},\n",
        "    {\"input\": \"quick\", \"output\": \"sluggish\", \"context\": \"speed\"},\n",
        "]\n",
        "\n",
        "print(\"=== 语义相似度示例选择器概念演示 ===\")\n",
        "print(\"语义相似度选择器会根据输入与示例的语义相似度来选择最相关的示例\")\n",
        "print(\"例如：\")\n",
        "print(\"- 输入'delighted'（高兴的）会选择情感相关的示例如'happy->sad'\")\n",
        "print(\"- 输入'rapid'（快速的）会选择速度相关的示例如'fast->slow'\")\n",
        "print(\"- 输入'elevated'（高的）会选择高度相关的示例如'tall->short'\")\n",
        "\n",
        "# 演示基于关键词的简化版本匹配\n",
        "def simple_semantic_select(input_word, examples, k=2):\n",
        "    \"\"\"简化版语义选择器演示\"\"\"\n",
        "    # 定义语义关键词组\n",
        "    emotion_words = [\"happy\", \"joyful\", \"delighted\", \"cheerful\", \"glad\"]\n",
        "    height_words = [\"tall\", \"high\", \"elevated\", \"towering\"]\n",
        "    speed_words = [\"fast\", \"quick\", \"rapid\", \"swift\"]\n",
        "    \n",
        "    # 根据输入词判断类别\n",
        "    if input_word.lower() in emotion_words:\n",
        "        category = \"emotion\"\n",
        "    elif input_word.lower() in height_words:\n",
        "        category = \"height\"\n",
        "    elif input_word.lower() in speed_words:\n",
        "        category = \"speed\"\n",
        "    else:\n",
        "        category = \"general\"\n",
        "    \n",
        "    # 选择相关示例\n",
        "    selected = [ex for ex in examples if ex.get(\"context\", \"general\") == category]\n",
        "    return selected[:k] if selected else examples[:k]\n",
        "\n",
        "# 测试语义选择\n",
        "test_words = [\"delighted\", \"elevated\", \"rapid\"]\n",
        "for word in test_words:\n",
        "    selected = simple_semantic_select(word, semantic_examples)\n",
        "    print(f\"\\n输入'{word}'选择的示例:\")\n",
        "    for example in selected:\n",
        "        print(f\"  {example['input']} -> {example['output']} (类别: {example['context']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 实际应用示例：多语言翻译助手\n",
        "\n",
        "让我们创建一个更实用的提示词模板系统，结合动态示例选择来构建一个智能翻译助手。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建翻译示例数据\n",
        "translation_examples = [\n",
        "    {\"english\": \"Hello, how are you?\", \"chinese\": \"你好，你好吗？\", \"type\": \"greeting\"},\n",
        "    {\"english\": \"Good morning!\", \"chinese\": \"早上好！\", \"type\": \"greeting\"},\n",
        "    {\"english\": \"I love programming.\", \"chinese\": \"我喜欢编程。\", \"type\": \"hobby\"},\n",
        "    {\"english\": \"Python is a great language.\", \"chinese\": \"Python是一门很棒的语言。\", \"type\": \"technology\"},\n",
        "    {\"english\": \"Let's have dinner together.\", \"chinese\": \"我们一起吃晚饭吧。\", \"type\": \"social\"},\n",
        "    {\"english\": \"The weather is nice today.\", \"chinese\": \"今天天气不错。\", \"type\": \"daily\"},\n",
        "]\n",
        "\n",
        "# 创建翻译示例的模板\n",
        "translation_example_prompt = PromptTemplate(\n",
        "    input_variables=[\"english\", \"chinese\"],\n",
        "    template=\"English: {english}\\nChinese: {chinese}\"\n",
        ")\n",
        "\n",
        "# 基于类型的简单选择器\n",
        "class TypeBasedExampleSelector:\n",
        "    def __init__(self, examples, k=3):\n",
        "        self.examples = examples\n",
        "        self.k = k\n",
        "    \n",
        "    def select_examples(self, input_variables):\n",
        "        # 简单的关键词匹配逻辑\n",
        "        text = input_variables.get(\"english\", \"\").lower()\n",
        "        \n",
        "        # 根据关键词判断类型\n",
        "        if any(word in text for word in [\"hello\", \"hi\", \"morning\", \"evening\"]):\n",
        "            example_type = \"greeting\"\n",
        "        elif any(word in text for word in [\"love\", \"like\", \"enjoy\"]):\n",
        "            example_type = \"hobby\"\n",
        "        elif any(word in text for word in [\"python\", \"programming\", \"code\", \"language\"]):\n",
        "            example_type = \"technology\"\n",
        "        elif any(word in text for word in [\"dinner\", \"lunch\", \"eat\", \"together\"]):\n",
        "            example_type = \"social\"\n",
        "        elif any(word in text for word in [\"weather\", \"today\", \"sunny\", \"rain\"]):\n",
        "            example_type = \"daily\"\n",
        "        else:\n",
        "            example_type = \"general\"\n",
        "        \n",
        "        # 选择相关示例\n",
        "        relevant_examples = [ex for ex in self.examples if ex.get(\"type\") == example_type]\n",
        "        if not relevant_examples:\n",
        "            relevant_examples = self.examples\n",
        "        \n",
        "        return relevant_examples[:self.k]\n",
        "\n",
        "# 创建智能翻译助手\n",
        "translation_selector = TypeBasedExampleSelector(translation_examples, k=2)\n",
        "\n",
        "translation_prompt = FewShotPromptTemplate(\n",
        "    example_selector=translation_selector,\n",
        "    example_prompt=translation_example_prompt,\n",
        "    prefix=\"\"\"You are a professional English-Chinese translator. \n",
        "Based on the following examples, translate the given English text to Chinese.\n",
        "Pay attention to the context and style of the examples.\"\"\",\n",
        "    suffix=\"English: {english}\\nChinese:\",\n",
        "    input_variables=[\"english\"]\n",
        ")\n",
        "\n",
        "# 测试不同类型的翻译\n",
        "test_sentences = [\n",
        "    \"Good evening, everyone!\",\n",
        "    \"I enjoy learning new programming languages.\",\n",
        "    \"Python makes coding more efficient.\",\n",
        "    \"Would you like to have coffee with me?\"\n",
        "]\n",
        "\n",
        "print(\"=== 智能翻译助手演示 ===\")\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\n输入: {sentence}\")\n",
        "    print(\"生成的提示词:\")\n",
        "    print(translation_prompt.format(english=sentence))\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 进阶技巧与最佳实践\n",
        "\n",
        "### 1. 提示词模板的最佳实践\n",
        "\n",
        "- **模块化设计**：将复杂的提示词分解为多个可重用的组件\n",
        "- **参数验证**：确保所有必需的参数都被正确传递\n",
        "- **上下文管理**：根据不同的使用场景选择合适的示例和格式\n",
        "- **性能优化**：合理设置示例选择器的参数以平衡效果和效率\n",
        "\n",
        "### 2. 示例选择器的选择策略\n",
        "\n",
        "- **LengthBasedExampleSelector**：适用于需要控制提示词长度的场景\n",
        "- **SemanticSimilarityExampleSelector**：适用于需要根据语义相似度选择示例的场景\n",
        "- **MaxMarginalRelevanceExampleSelector**：平衡相似度和多样性\n",
        "- **自定义选择器**：根据特定业务逻辑实现定制化的选择策略\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 演示高级提示词模板技巧\n",
        "\n",
        "# 1. 带条件逻辑的提示词模板\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "conditional_template = \"\"\"\n",
        "你是一个{role}。\n",
        "{%- if difficulty == \"beginner\" %}\n",
        "请用简单易懂的语言回答问题。\n",
        "{%- elif difficulty == \"advanced\" %}\n",
        "请提供深入的技术分析和详细解释。\n",
        "{%- else %}\n",
        "请提供平衡的回答，既有概述也有一些技术细节。\n",
        "{%- endif %}\n",
        "\n",
        "用户问题：{question}\n",
        "\"\"\"\n",
        "\n",
        "# 注意：上面的模板使用了Jinja2语法，在实际使用中需要相应的模板引擎支持\n",
        "\n",
        "# 2. 多层次验证的提示词模板\n",
        "class ValidatedPromptTemplate:\n",
        "    def __init__(self, template, required_vars, optional_vars=None):\n",
        "        self.template = template\n",
        "        self.required_vars = required_vars\n",
        "        self.optional_vars = optional_vars or []\n",
        "    \n",
        "    def format(self, **kwargs):\n",
        "        # 验证必需参数\n",
        "        missing_vars = [var for var in self.required_vars if var not in kwargs]\n",
        "        if missing_vars:\n",
        "            raise ValueError(f\"缺少必需参数: {missing_vars}\")\n",
        "        \n",
        "        # 设置可选参数的默认值\n",
        "        for var in self.optional_vars:\n",
        "            if var not in kwargs:\n",
        "                kwargs[var] = \"\"\n",
        "        \n",
        "        return self.template.format(**kwargs)\n",
        "\n",
        "# 创建验证模板\n",
        "validated_template = ValidatedPromptTemplate(\n",
        "    template=\"作为{role}，请回答关于{topic}的问题：{question}。{additional_context}\",\n",
        "    required_vars=[\"role\", \"topic\", \"question\"],\n",
        "    optional_vars=[\"additional_context\"]\n",
        ")\n",
        "\n",
        "# 测试验证功能\n",
        "try:\n",
        "    # 正确使用\n",
        "    prompt1 = validated_template.format(\n",
        "        role=\"Python专家\",\n",
        "        topic=\"数据结构\",\n",
        "        question=\"什么是字典？\",\n",
        "        additional_context=\"请举例说明。\"\n",
        "    )\n",
        "    print(\"✅ 正确的提示词生成:\")\n",
        "    print(prompt1)\n",
        "    \n",
        "    # 缺少必需参数的情况\n",
        "    prompt2 = validated_template.format(\n",
        "        role=\"Python专家\",\n",
        "        question=\"什么是字典？\"\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(f\"\\n❌ 参数验证失败: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# 3. 动态角色切换的提示词系统\n",
        "class RoleBasedPromptSystem:\n",
        "    def __init__(self):\n",
        "        self.roles = {\n",
        "            \"teacher\": {\n",
        "                \"prefix\": \"作为一名经验丰富的教师，\",\n",
        "                \"style\": \"教育性的、循序渐进的\",\n",
        "                \"examples\": [\"让我来解释一下...\", \"首先我们需要理解...\"]\n",
        "            },\n",
        "            \"consultant\": {\n",
        "                \"prefix\": \"作为专业顾问，\",\n",
        "                \"style\": \"分析性的、解决方案导向的\",\n",
        "                \"examples\": [\"基于分析，我建议...\", \"从商业角度来看...\"]\n",
        "            },\n",
        "            \"friend\": {\n",
        "                \"prefix\": \"作为你的朋友，\",\n",
        "                \"style\": \"轻松友好的、支持性的\",\n",
        "                \"examples\": [\"我觉得...\", \"你可以试试...\"]\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def create_prompt(self, role, topic, question):\n",
        "        role_info = self.roles.get(role, self.roles[\"teacher\"])\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "{role_info['prefix']}我将以{role_info['style']}方式来回答你的问题。\n",
        "\n",
        "主题：{topic}\n",
        "问题：{question}\n",
        "\n",
        "回答方式示例：{role_info['examples'][0]}\n",
        "\"\"\"\n",
        "        return prompt.strip()\n",
        "\n",
        "# 测试角色切换系统\n",
        "role_system = RoleBasedPromptSystem()\n",
        "\n",
        "test_question = \"如何学习机器学习？\"\n",
        "roles_to_test = [\"teacher\", \"consultant\", \"friend\"]\n",
        "\n",
        "print(\"=== 动态角色切换演示 ===\")\n",
        "for role in roles_to_test:\n",
        "    print(f\"\\n【{role.upper()}角色】\")\n",
        "    prompt = role_system.create_prompt(role, \"机器学习\", test_question)\n",
        "    print(prompt)\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 性能优化与调试技巧\n",
        "\n",
        "### 1. 提示词长度优化\n",
        "- 监控生成的提示词长度，避免超出模型的上下文限制\n",
        "- 使用示例选择器动态调整示例数量\n",
        "- 合理设置`max_length`参数以平衡效果和效率\n",
        "\n",
        "### 2. 调试和测试\n",
        "- 打印生成的完整提示词以验证格式\n",
        "- 测试边界情况（空输入、超长输入等）\n",
        "- 验证示例选择的准确性和相关性\n",
        "\n",
        "### 3. 缓存和重用\n",
        "- 对于相同参数组合，缓存生成的提示词\n",
        "- 重用经过验证的示例数据集\n",
        "- 模块化设计以提高代码复用性\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 性能优化和调试工具演示\n",
        "\n",
        "class PromptAnalyzer:\n",
        "    \"\"\"提示词分析和优化工具\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.metrics = {}\n",
        "    \n",
        "    def analyze_prompt(self, prompt_text, name=\"unnamed\"):\n",
        "        \"\"\"分析提示词的各项指标\"\"\"\n",
        "        lines = prompt_text.split('\\n')\n",
        "        words = prompt_text.split()\n",
        "        \n",
        "        analysis = {\n",
        "            \"name\": name,\n",
        "            \"total_length\": len(prompt_text),\n",
        "            \"word_count\": len(words),\n",
        "            \"line_count\": len(lines),\n",
        "            \"avg_line_length\": sum(len(line) for line in lines) / len(lines) if lines else 0,\n",
        "            \"max_line_length\": max(len(line) for line in lines) if lines else 0\n",
        "        }\n",
        "        \n",
        "        self.metrics[name] = analysis\n",
        "        return analysis\n",
        "    \n",
        "    def compare_prompts(self, prompt1, prompt2, name1=\"Prompt 1\", name2=\"Prompt 2\"):\n",
        "        \"\"\"比较两个提示词的指标\"\"\"\n",
        "        analysis1 = self.analyze_prompt(prompt1, name1)\n",
        "        analysis2 = self.analyze_prompt(prompt2, name2)\n",
        "        \n",
        "        print(f\"=== 提示词比较: {name1} vs {name2} ===\")\n",
        "        print(f\"总长度: {analysis1['total_length']} vs {analysis2['total_length']}\")\n",
        "        print(f\"词数: {analysis1['word_count']} vs {analysis2['word_count']}\")\n",
        "        print(f\"行数: {analysis1['line_count']} vs {analysis2['line_count']}\")\n",
        "        print(f\"平均行长: {analysis1['avg_line_length']:.1f} vs {analysis2['avg_line_length']:.1f}\")\n",
        "        \n",
        "        return analysis1, analysis2\n",
        "    \n",
        "    def suggest_optimization(self, prompt_text):\n",
        "        \"\"\"提供优化建议\"\"\"\n",
        "        analysis = self.analyze_prompt(prompt_text)\n",
        "        suggestions = []\n",
        "        \n",
        "        if analysis['total_length'] > 2000:\n",
        "            suggestions.append(\"⚠️ 提示词过长，建议缩短或使用示例选择器\")\n",
        "        \n",
        "        if analysis['max_line_length'] > 100:\n",
        "            suggestions.append(\"📝 某些行过长，建议分行提高可读性\")\n",
        "        \n",
        "        if analysis['word_count'] < 10:\n",
        "            suggestions.append(\"💡 提示词可能过于简单，建议添加更多上下文\")\n",
        "        \n",
        "        return suggestions\n",
        "\n",
        "# 使用分析工具\n",
        "analyzer = PromptAnalyzer()\n",
        "\n",
        "# 分析之前创建的翻译提示词\n",
        "sample_prompt = translation_prompt.format(english=\"Hello, how are you today?\")\n",
        "suggestions = analyzer.suggest_optimization(sample_prompt)\n",
        "\n",
        "print(\"=== 提示词性能分析 ===\")\n",
        "analysis = analyzer.analyze_prompt(sample_prompt, \"翻译助手提示词\")\n",
        "\n",
        "for key, value in analysis.items():\n",
        "    if key != \"name\":\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "if suggestions:\n",
        "    print(\"\\n=== 优化建议 ===\")\n",
        "    for suggestion in suggestions:\n",
        "        print(suggestion)\n",
        "else:\n",
        "    print(\"\\n✅ 提示词指标良好，无需优化\")\n",
        "\n",
        "print(\"\\n=== 调试技巧演示 ===\")\n",
        "print(\"1. 完整提示词预览:\")\n",
        "print(\"--- 开始 ---\")\n",
        "print(sample_prompt)\n",
        "print(\"--- 结束 ---\")\n",
        "\n",
        "print(f\"\\n2. 字符计数: {len(sample_prompt)} 字符\")\n",
        "print(f\"3. Token估算 (粗略): ~{len(sample_prompt.split()) * 1.3:.0f} tokens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vehXwrdxG08-",
        "outputId": "b8665780-fbf7-4329-dd3d-5e0602837bf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_selector.get_text_length(\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM7vOFz/ctj6hEBoPcJqCn6",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
